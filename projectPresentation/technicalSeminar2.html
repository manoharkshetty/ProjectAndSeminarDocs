<!doctype html>
<html lang="en">    
<head>
    <meta charset="utf-8">
    <title>Reveal.js 3 Slide Demo</title>
    <link rel="stylesheet" href="css/reveal.min.css">
    <link rel="stylesheet" href="css/theme/default.css" id="theme">    
    <!--Add support for earlier versions of Internet Explorer -->
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
    <style >

    .presented_by{
        float: right;
    }
    </style>
</head>
 
<body>
    <!-- Wrap the entire slide show in a div using the "reveal" class. -->
    <div class="reveal">
        <!-- Wrap all slides in a single "slides" class -->
        <div class="slides">
 
            <!-- ALL SLIDES GO HERE -->
            <!-- Each section element contains an individual slide -->
            <section>
                 <table>   
            <tr><td>       
                <img src="img/col_logo.png" width="100px" height="100px" style="margin:-30px 0px;" /></td>
                <td >
                <h2 style="margin-top:-50px">SJB Institute of Technology</h2></td>
                <td> <img src="img/swamiji.png" width="100px" height="100px" style="margin:-30px 0px;" /></td></td></tr>
            </table>

              
               <h4>Dept. of Computer Science & Engineering</h4>
               <p style="margin-top:50px;">A Technical Seminar On</p>
              <h3 style="margin-top:20px">Paper Based Augmented Reality</h3><h2> and</h2> 
             <h3> Haptic System for Eyes Free and Hands Free Pedestrian Navigation</h3>
                  <div class="presented_by">
                  <table >
                    <tr >
                    <td>
                     <div style="margin-top:20px">
                        <h4 style="margin-left:80px">BY</h4>
                        <p >Manohara. K </p>
                        <p>(1JB10CS054)</p></div>
                       
                    </td>
                    <td>
                        <div style="margin-top:20px;" >
                        <H4  style="margin-left:380px;"> Under The Guidance Of</h4>
                         <p>style="margin-left:400px"> Mrs. Chaitra.M</p>
                         <p style="margin-left:400px">Asst. professor</p></div>
                    </td>
                    </tr>
                    </table>    
            </section>
 
            <section id="show-a-link">
                   <h2>AGENDA</h2>
                <ul style="list-style:">
                <li>Introduction</li>
                <li>Algorithm Outline</li>
                <li>Text Patch Recognition</li>
                <li>Applications</li>
                <li>Haptic System for Eyes Free and Hands Free Pedestrian Navigation</li>
                <li>Conclusions and Future Work</li>
                <li>References</li>
                </ul>
            </ul>
            </section>
 
            <section>
                  <h2>Introduction</h2>
                <ul>
                <li>Augmented Reality (AR) is a new technology
                that involves the overlay of computer graphics on the real world </li>
                <li>Linking the physical and digital worlds is a long
                    standing goal of augmented reality.</li>
                    <li>This paper proposes a new method of interacting with
                     documents termed Paper-Based Augmented Reality that
                    links patches of text to electronic data and uses a camera
                    phone as the recognition device.</li>
                </ul>
               
            </section>
            <section>
                <img src="img/pbar.jpg" width="600px" height="400px">
                <p>Figure 1: Creating and using paper-based augmented reality documents: </p>
            </section>
             <section>
                <img src="img/pbar2.jpg" width="600px" height="400px">
                <p>Figure 1:  Electronic data is added to paper documents
					without changing the appearance of the paper document
					in any way </p>
            </section>
            <section>
                 <h2>Algorithm Outline</h2>
                <ul>
                <li> PBAR-enabled documents are created by scanning a document and indexing it for text patch recognition</li>
                <li>Data is associated with regions on the document by choosing “hot spots” that are rectangular patches of text, and adding data to the hot spots</li>
                <li>The index information and symbolic hot spot data are stored in the PBAR database.</li>
                <li>A simple example of data in a hotspot is a URL that points to a web page. </li></ul>


            </section>
            <section>
                  <h2>Text Patch Recognition</h2>
                     <ul><li>The objective of the text patch recognition algorithm is to correctly determine the identity
                      of a page and the x-y position in the page of a small patch of text.</li>
                     <li>The
technical challenge is that shows the typical quality of images produced by commonly available camera phones.</li>
                     <li>it
                        is still possible in almost every case to identify the
                        bounding boxes around words since the spaces between
                        words and lines can still be distinguished</li>
                     </ul>
            </section>
            <section>
            <h2>Applications</h2>
                <ul>
                      <li><ul><p>Travel Guidebook</p>
                      <li>Travel guidebooks are almost out-of-date the minute they are printed.</li>
                        <li>PBAR allows someone to point a camera phone at the text that describes the facility and
retrieve the currently available information about it.</li></ul></li>
                    <li><ul><p style="margin-top:20px">Self-Printed Documents</p>
                      <li>Documents that are printed on a desktop PC are
typically created by individuals for their personal use.</li>
                        <li> PBAR allows users to customize the interactivity of
those documents based on their own needs and permits the database to be under the user’s personal control:</li></ul></li>   </ul>
                        </section>
                      
     <section>
            <h2>Haptic System for Eyes Free and Hands Free Pedestrian Navigation</h2>
                <ul>
                      
                      <li>Until now Augmented Reality was mainly associated with visual
                            augmentation, which is often reduced to superimposing a virtual
                                object onto a real object</li>
                        <li>We present in this document a vibro-tactile system called
                            HaptiNav, which illustrates the concept of Haptic
                            Augmented Reality.</li>
                   <li> statistical analysis of the mental load, frustration
and effort highlights the advantages of HaptiNav compared
to two other systems.</li>  </ul>
                        </section>
            <section>
	
            <section>
            	
            	<h2>Conclusion</h2>
            	<ul><li>A new paradigm for augmented reality was described
					in which electronic data is added to paper documents
					without changing the appearance of the paper document
					in any way. </li>
					<li>Two of the
					applications that we’ve created were presented: an
					augmented travel guidebook and Clickable Paper. Both
					of them show the potential value of paper-based
					augmented reality for common applications.</li></ul>
            </section>
            <section>
                <h2>Future papers</h2>
                <ul>
                <li>Joystick mapped Augmented Reality Cues for End-Effector controlled Tele-
                    operated Robots<br />
            Aditya Nawab ,Keshav Chintamani1, Darin Ellis, Gregory Auner, Abhilash Pandya </li>
                <li style="margin-top:20px">What Wearable Augmented
Reality Can Do for You<br />Bruce H. Thomas and Christian Sandor

                    </li>
            </section>
            <section>
                   <h2>REFERENCES</h2>
            <ol style="list-style:none">
            <li>[1]. E. Bier, M. Stone and K. Pier, “Enhanced Illustration Using
Magic Lens Filters,” IEEE Computer Graphics and
Applications, v. 17, no. 6, 62-70, Nov. 1997.</li>
<li>[2]. M. N. Billinghurst and A. Henrysson, “Research Directions
in Handheld AR,” Int. Journal of Virtual Reality, v. 5 no. 2,
51-58, 2006.</li>
<li>[3]. P. Fuchs, G. Moreau, S. Donikian, 38 auteurs, Le traité de
la réalité virtuelle, troisième édition, cinquième volume :
« Les humains virtuels ». Les Presses de l’Ecole Mines
ParisTech. ISBN 978-2-911256-00-4, March 2009.</li>
<li>[4] R. Azuma, Y. Baillot, R. Behringer, S. Feiner, S. Julier, and
B. Mac- Intyre. Recent advances in augmented reality.
IEEE Comput.Grap</li>
</ol>
            </section>
            <section>
               
                <h1>THANK YOU</h1>
            </section>
 
            </div>
    </div>
    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.min.js"></script>
  <script type="text/javascript" src="js/jquery-1.11.0.js"></script>
    <script>
        // Required, even if empty.
        Reveal.initialize({
        });
     
    </script>
</body>
</html>